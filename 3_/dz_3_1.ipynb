{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8605add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "import torchvision as tv\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1713a49",
   "metadata": {},
   "source": [
    "### FashionMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "386d91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78da680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset  = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3fac324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd1670d3860>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAASQElEQVR4nO3dbYxUZZYH8P8RAXmTdxCBXYZR4+ImKytBopPVdbITQBPEOGb4sKIh22MEnTF8WOJq8MskRndmdj5sJulZZWAzw2QSYCHGFxAnEWKYgIjIi4u8SUO3zZsISEPzcvZDX9werHtOU09V3WrO/5eQ6r6nn6rTt/pwq+rc5z6iqiCia991RSdARLXBYicKgsVOFASLnSgIFjtRENfX8sFEhB/911iPHj3M+JAhQ5LGX7hwwYwfO3YsN8ZOUHWoqpTanlTsIjIVwK8A9ADwX6r6csr9RSVS8rn5RkpRDBw40Iw/9thjZrx///5m/MSJE2Z8yZIlubG2tjZzLFVW2S/jRaQHgP8EMA3ABACzRGRCpRIjospKec8+GcBuVd2rqu0A/gBgRmXSIqJKSyn20QCaOn1/MNv2F0SkQUQ2icimhMciokQp79lLvdH81ptLVW0E0AjwAzqiIqUc2Q8CGNvp+zEAmtPSIaJqSSn2jQBuFZHviEgvAD8CsKoyaRFRpUlKW0dEpgP4D3S03l5X1Z85P8+X8VUwZ86c3NiUKVPMsTt27DDjGzduNOP33HOPGb/77rtzYxs2bDDHvvrqq2bcY50jcPHixaT7rmdV6bOr6psA3ky5DyKqDZ4uSxQEi50oCBY7URAsdqIgWOxEQbDYiYJI6rNf9YMF7bOnTmF99tlnzfjNN9+cG1uwYIE5tkhLly4142fPnjXjTz75ZNmPfd119nHu0qVLZd930fL67DyyEwXBYicKgsVOFASLnSgIFjtRECx2oiDYesuktMd69epljm1vbzfjU6dONeMPPvigGX/mmWfMuKVnz55m/Pz582a8mi2s5cuXm3Fviuwrr7ySG0v9vesZW29EwbHYiYJgsRMFwWInCoLFThQEi50oCBY7URDss2e8Pvv11+dfiDe1J+v1k72VVq1lk628vbH1btMme0WxJ554Ije2bds2c2x33m/ssxMFx2InCoLFThQEi50oCBY7URAsdqIgWOxEQSSt4not8c43sJb/9frsL774ohnfunWrGfd6un369MmNtbW1mWOLlDoXftGiRWZ83rx5ubGnnnrKHOvl1h0lFbuI7AdwCsBFABdUdVIlkiKiyqvEkf0fVfVoBe6HiKro2nutQkQlpRa7AlgtIh+KSEOpHxCRBhHZJCL2icxEVFWpL+PvVdVmERkBYI2IfKqq73f+AVVtBNAI1PdEGKJrXdKRXVWbs9vDAFYAmFyJpIio8soudhHpJyIDLn8N4AcA7HmDRFSYsuezi8h4dBzNgY63A79X1Z85Y0K+jH/77bfN+MyZM8241yu35l7X87zrai+b/N577+XGHnjggaT7rucln/Pms5f9nl1V9wL4u7IzIqKaYuuNKAgWO1EQLHaiIFjsREGw2ImCuGamuKYsuQyktVKmTZtmjm1ubjbjqdNQU9prqfsthdeeSr2c8759+3JjM2bMMMeuXLnSjHv7rcj9modHdqIgWOxEQbDYiYJgsRMFwWInCoLFThQEi50oiG7VZ7d64dalngG/J5syJfHRRx814+vWrSv7voH6nk5ZTV6v2rN79+7cmDfF1euzX7x4saycisQjO1EQLHaiIFjsREGw2ImCYLETBcFiJwqCxU4URLfqs1v95CJ7zdOnTzfjb731VlUfP6UfXcS86q5KvQx2U1NTbqyhoeRqZd9YuHChGT9x4oQZ7927txm3+vReD7/c54xHdqIgWOxEQbDYiYJgsRMFwWInCoLFThQEi50oiG7VZy/SbbfdlhvbsmWLOTZ17nPKOQTeXPjU65unjK92j3/MmDG5Me/6B7fffrsZ37Bhgxk/d+6cGS+Ce2QXkddF5LCIbOu0bYiIrBGRz7LbwdVNk4hSdeVl/G8BTL1i2wIAa1X1VgBrs++JqI65xa6q7wM4fsXmGQAWZ18vBvBwZdMiokor9z37SFVtAQBVbRGREXk/KCINAOwTkYmo6qr+AZ2qNgJoBAARqd9ZF0TXuHJbb60iMgoAstvDlUuJiKqh3GJfBWB29vVsAPZ1d4mocNKFPupSAPcDGAagFcBCAP8D4I8A/grAAQA/VNUrP8QrdV9JL+OXLVuWG7vjjjvMsa2trWZ82LBhZvzAgQO5saNHj5pjvXXGV69ebcZXrFhhxr251VHNnTs3NzZ+/HhzrPV8A/5z7p0bMXTo0NzYBx98YI7dvHmzGVfVkic/uO/ZVXVWTuj73lgiqh88XZYoCBY7URAsdqIgWOxEQbDYiYJwW28VfbDE1ts777yTG7vlllvMsd5lib0piWfPns2NeW27w4ftc4569eplxr3crWmsixcvzo0BwPLly834V199ZcZ79uxpxq2W6EMPPVT2WACYMGGCGT927FhubOTIkebYL7/80ox7z1mfPn3M+ODB+RNFV61aZY59/PHHzXhe641HdqIgWOxEQbDYiYJgsRMFwWInCoLFThQEi50oiG51KWlr2qB3vsDp06fN+Pnz58241YfftWuXOdbrRR8/bs8ObmtrM+PDhw/PjT399NPmWGsaKAB8/fXXZty7VLXFe07OnDljxg8dOlT2Y3vnPtxwww1m/PPPPzfjffv2NePW7+493+XikZ0oCBY7URAsdqIgWOxEQbDYiYJgsRMFwWInCqJb9dl79+6dGxswYIA5NnV+8o033pgb83rNR44cMePt7e1m3FteeM+ePbkxa043YP9egL9fvV54Ss/YW+rausYAYM8p957vm266KemxvfM+rMuLe3+r5eKRnSgIFjtRECx2oiBY7ERBsNiJgmCxEwXBYicKolv12a251V6v2ltC1+uLNjc358a8ufBe3Ot1e312b768xZtTPnDgQDM+YsQIM75jx47cmLeUtfd7eT1+a1llb5/u3bvXjHvz1fft22fG77rrrtxYU1OTObZc7pFdRF4XkcMisq3TtpdE5JCIbMn+Ta9KdkRUMV15Gf9bAFNLbP+lqt6Z/XuzsmkRUaW5xa6q7wOwr5tERHUv5QO6eSKyNXuZn7twlYg0iMgmEdmU8FhElKjcYv81gO8CuBNAC4Cf5/2gqjaq6iRVnVTmYxFRBZRV7KraqqoXVfUSgN8AmFzZtIio0soqdhEZ1enbmQC25f0sEdUHt88uIksB3A9gmIgcBLAQwP0icicABbAfwI+rl+L/s3rC3nW+vT66N7956NChuTFvPrvX4/fWX/dys+aMe+vOi5Rcyvsb3jXtvfXbrX62N1fe67P369fPjA8aNCg35u0X7+9l2LBhZtz7m5g0Kf9d7XPPPWeOLZdb7Ko6q8Tm16qQCxFVEU+XJQqCxU4UBIudKAgWO1EQLHaiILrVFFerzeNNxfRac157y5qm6rVxvNab16axLqEN2Ll7bT3vksjefkmJe9NEvbagl7s1hdZr23lx7zn3crOmZHtTosvFIztRECx2oiBY7ERBsNiJgmCxEwXBYicKgsVOFES36rNbl3P2pkN6lw72erpW3Lsksrf0sMfr01u/m5eb18P34t5+s54Xb6zXb/bGW/vF+3vx7tu7BLeX+65du3Jjn376qTm2XDyyEwXBYicKgsVOFASLnSgIFjtRECx2oiBY7ERBdKs++7Fjx6p23968b4vXs0291LQn5RwAL96nTx8z7p1DkPK7eedGeOcAeOMtqc+pd/0Ea5lu7/Lc5eKRnSgIFjtRECx2oiBY7ERBsNiJgmCxEwXBYicKolv12bdty18GvrW1Nem+vb6qNT85pZ/blfFePHW+vMW7Lrx3foIV93r83rLJKT18b6y3T73ryjc1NZnxPXv2mPFqcI/sIjJWRP4kIjtFZLuI/CTbPkRE1ojIZ9nt4OqnS0Tl6srL+AsA5qvq3wCYAmCuiEwAsADAWlW9FcDa7HsiqlNusatqi6puzr4+BWAngNEAZgBYnP3YYgAPVylHIqqAq3rPLiLjAEwE8GcAI1W1Bej4D0FERuSMaQDQkJgnESXqcrGLSH8AywD8VFVPehfku0xVGwE0Zvdhf+JCRFXTpdabiPRER6H/TlWXZ5tbRWRUFh8F4HB1UiSiSnCP7NJxCH8NwE5V/UWn0CoAswG8nN2urEqGnXz00Ue5sZEjR5pjT548aca99pbVBvLGVrvFZE239MamToH1WlRW6y5lmeyusParN0XVW5LZa9UOHz7cjH/88cdmvBq68jL+XgD/DOATEdmSbXseHUX+RxGZA+AAgB9WJUMiqgi32FV1PYC8N+jfr2w6RFQtPF2WKAgWO1EQLHaiIFjsREGw2ImC6FZTXK1eeUtLiznWuyTyqVOnzHjKNFav1+2djej1hK1+stcP9nrdRZ4DkPJ7p/L2i5f76NGjzfgbb7xx1Tml4pGdKAgWO1EQLHaiIFjsREGw2ImCYLETBcFiJwqiW/XZLRs3bjTjU6ZMMeNeT9fqu3r93ra2NjPu8XKz5pR7/WJvvro3p9zLzTqHwJsL7+WWcilp79yGlEtkA/6SzevWrTPj1cAjO1EQLHaiIFjsREGw2ImCYLETBcFiJwqCxU4UhFRzTvC3HqyKK8L07dvXjG/fvt2Mp8zb9vroXi/ai3tz0q3xXq/ak9pnT/n78sZ6fXorN+++vT68d30Da40DAHjkkUfMeApVLZk8j+xEQbDYiYJgsRMFwWInCoLFThQEi50oCBY7URBdWZ99LIAlAG4CcAlAo6r+SkReAvAvAI5kP/q8qr5ZrUQ9Z86cMeOLFi0y4/Pnzzfj+/bty42lzOkG/J6vN3fakjLnGwDa29vNeOp15VPu2zv/wBqfOp990KBBZvyFF14w45bUv5c8XTnj4gKA+aq6WUQGAPhQRNZksV+q6r+X9chEVFNdWZ+9BUBL9vUpEdkJwF7ugojqzlW9ZxeRcQAmAvhztmmeiGwVkddFZHDOmAYR2SQim9JSJaIUXS52EekPYBmAn6rqSQC/BvBdAHei48j/81LjVLVRVSep6qT0dImoXF0qdhHpiY5C/52qLgcAVW1V1YuqegnAbwBMrl6aRJTKLXbp+GjwNQA7VfUXnbaP6vRjMwFsq3x6RFQp7hRXEfkegHUAPkFH6w0AngcwCx0v4RXAfgA/zj7Ms+6rdvNpr9K7775rxidOnJgbO3funDnWmw45YsQIM07l+eKLL3JjXkvQmzK9atUqMz579mwzXk15U1y78mn8egClBhfWUyeiq8cz6IiCYLETBcFiJwqCxU4UBIudKAgWO1EQ18ylpKvtvvvuy42NGzfOHDtgwAAz7l0S2bucs9XH96ZLenEvN69f7Y23eH+b3vkN1iW+vXMfWltbzfj69evNeJF4KWmi4FjsREGw2ImCYLETBcFiJwqCxU4UBIudKIha99mPAPi806ZhAI7WLIGrU6+51WteAHMrVyVz+2tVHV4qUNNi/9aDi2yq12vT1Wtu9ZoXwNzKVavc+DKeKAgWO1EQRRd7Y8GPb6nX3Oo1L4C5lasmuRX6np2IaqfoIzsR1QiLnSiIQopdRKaKyP+KyG4RWVBEDnlEZL+IfCIiW4peny5bQ++wiGzrtG2IiKwRkc+y25Jr7BWU20sicijbd1tEZHpBuY0VkT+JyE4R2S4iP8m2F7rvjLxqst9q/p5dRHoA2AXgnwAcBLARwCxV3VHTRHKIyH4Ak1S18BMwROQfAJwGsERV/zbb9gqA46r6cvYf5WBV/dc6ye0lAKeLXsY7W61oVOdlxgE8DOAJFLjvjLweQw32WxFH9skAdqvqXlVtB/AHADMKyKPuqer7AI5fsXkGgMXZ14vR8cdSczm51QVVbVHVzdnXpwBcXma80H1n5FUTRRT7aABNnb4/iPpa710BrBaRD0WkoehkShh5eZmt7Lbe1o5yl/GupSuWGa+bfVfO8uepiij2UtfHqqf+372q+vcApgGYm71cpa7p0jLetVJimfG6UO7y56mKKPaDAMZ2+n4MgOYC8ihJVZuz28MAVqD+lqJuvbyCbnZ7uOB8vlFPy3iXWmYcdbDvilz+vIhi3wjgVhH5joj0AvAjAPaSmDUiIv2yD04gIv0A/AD1txT1KgCXlwidDWBlgbn8hXpZxjtvmXEUvO8KX/5cVWv+D8B0dHwivwfAvxWRQ05e4wF8nP3bXnRuAJai42XdeXS8IpoDYCiAtQA+y26H1FFu/42Opb23oqOwRhWU2/fQ8dZwK4At2b/pRe87I6+a7DeeLksUBM+gIwqCxU4UBIudKAgWO1EQLHaiIFjsREGw2ImC+D9mWIFhSjZ+fgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[100][0].numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4a538f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118ce018",
   "metadata": {},
   "source": [
    "### Сверточные слои и архитектура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1949ba2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"); dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01cd9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_iter, dev):    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        acc_sum = 0\n",
    "        count = 0\n",
    "        for X, y in test_iter:\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            acc_sum += (model(X).argmax(axis=1) == y).sum().item()\n",
    "            count += y.shape[0]\n",
    "        return acc_sum / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19d773eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(train_iter, test_iter, model, epochs, trainer):\n",
    "    dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    model = model.to(dev)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss(reduction='sum')\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss_sum, train_acc_sum, count, start = 0.0, 0.0, 0, time.time()\n",
    "        \n",
    "        model.train()\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            X, y = X.to(dev), y.to(dev)\n",
    "            predict = model(X)\n",
    "            l = loss(predict, y)\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss_sum += l.item()\n",
    "            train_acc_sum += (predict.argmax(axis=1) == y).sum().item()\n",
    "            count += y.shape[0]\n",
    "                        \n",
    "        train_acc = train_acc_sum / count\n",
    "        train_loss  = train_loss_sum / count\n",
    "        test_acc = evaluate(model, test_iter, dev)\n",
    "        run = time.time() - start\n",
    "        \n",
    "        print(f\"epoch = {epoch}, train_acc = {train_acc:.7f}, train_loss = {train_loss:.7f}, test_acc = {test_acc:.7f}, time = {run:.7f}\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3fb1b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(32, 64, kernel_size=2, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Conv2d(64, 64, kernel_size=3, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d( 2, stride=2),\n",
    "    nn.Conv2d(64, 32, kernel_size=3, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(288, 288),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(288, 72),\n",
    "    nn.BatchNorm1d(72),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(72, 10),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fe6a6199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 28, 28])\n",
      "Layer Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1)). X shape: torch.Size([1, 32, 29, 29])\n",
      "Layer ReLU(). X shape: torch.Size([1, 32, 29, 29])\n",
      "Layer MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False). X shape: torch.Size([1, 32, 14, 14])\n",
      "Layer Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2)). X shape: torch.Size([1, 64, 17, 17])\n",
      "Layer ReLU(). X shape: torch.Size([1, 64, 17, 17])\n",
      "Layer MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False). X shape: torch.Size([1, 64, 8, 8])\n",
      "Layer Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2)). X shape: torch.Size([1, 64, 10, 10])\n",
      "Layer ReLU(). X shape: torch.Size([1, 64, 10, 10])\n",
      "Layer MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False). X shape: torch.Size([1, 64, 5, 5])\n",
      "Layer Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2)). X shape: torch.Size([1, 32, 7, 7])\n",
      "Layer ReLU(). X shape: torch.Size([1, 32, 7, 7])\n",
      "Layer MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False). X shape: torch.Size([1, 32, 3, 3])\n",
      "Layer Flatten(). X shape: torch.Size([1, 288])\n",
      "Layer Linear(in_features=288, out_features=288, bias=True). X shape: torch.Size([1, 288])\n",
      "Layer Dropout(p=0.5, inplace=False). X shape: torch.Size([1, 288])\n",
      "Layer ReLU(). X shape: torch.Size([1, 288])\n",
      "Layer Linear(in_features=288, out_features=72, bias=True). X shape: torch.Size([1, 72])\n",
      "-------- Expected more than 1 value per channel when training, got input size torch.Size([1, 72])\n",
      "Layer BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True). X shape: torch.Size([1, 72])\n",
      "Layer ReLU(). X shape: torch.Size([1, 72])\n",
      "Layer Linear(in_features=72, out_features=10, bias=True). X shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "def test_shape(model, X):\n",
    "    X = X.reshape(1, 1, 28, 28)\n",
    "    print(X.shape)\n",
    "    for l in model:\n",
    "        try:\n",
    "            X = l(X)\n",
    "        except Exception as ex: \n",
    "            print('--------', ex) # при проверке shape, BatchNorm выдает ошибку, но в сети работает\n",
    "        print(\"Layer {}. X shape: {}\".format(l, X.shape))\n",
    "\n",
    "test_shape(model, train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "536da669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  (7): ReLU()\n",
       "  (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (9): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "  (10): ReLU()\n",
       "  (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (12): Flatten()\n",
       "  (13): Linear(in_features=288, out_features=288, bias=True)\n",
       "  (14): Dropout(p=0.5, inplace=False)\n",
       "  (15): ReLU()\n",
       "  (16): Linear(in_features=288, out_features=72, bias=True)\n",
       "  (17): BatchNorm1d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Linear(in_features=72, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"); dev\n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f9c5011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "learing_rate = 0.0003\n",
    "trainer = torch.optim.AdamW(model.parameters(), lr=learing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27cbd667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1, train_acc = 0.6895167, train_loss = 1.0424221, test_acc = 0.8153000, time = 6.2749248\n",
      "epoch = 2, train_acc = 0.8457333, train_loss = 0.4840154, test_acc = 0.8557000, time = 6.2149146\n",
      "epoch = 3, train_acc = 0.8732833, train_loss = 0.3725885, test_acc = 0.8799000, time = 6.2625146\n",
      "epoch = 4, train_acc = 0.8890833, train_loss = 0.3213399, test_acc = 0.8904000, time = 6.3999116\n",
      "epoch = 5, train_acc = 0.8976333, train_loss = 0.2896515, test_acc = 0.8940000, time = 6.3853624\n",
      "epoch = 6, train_acc = 0.9052167, train_loss = 0.2681109, test_acc = 0.8969000, time = 6.4377809\n",
      "epoch = 7, train_acc = 0.9116500, train_loss = 0.2498018, test_acc = 0.9082000, time = 6.4530864\n",
      "epoch = 8, train_acc = 0.9166500, train_loss = 0.2360191, test_acc = 0.9053000, time = 6.3488133\n",
      "epoch = 9, train_acc = 0.9198833, train_loss = 0.2254239, test_acc = 0.9088000, time = 6.3597789\n",
      "epoch = 10, train_acc = 0.9240833, train_loss = 0.2145508, test_acc = 0.9076000, time = 6.4247615\n",
      "epoch = 11, train_acc = 0.9273333, train_loss = 0.2050227, test_acc = 0.9160000, time = 6.2880087\n",
      "epoch = 12, train_acc = 0.9292833, train_loss = 0.1985629, test_acc = 0.9094000, time = 6.4092100\n",
      "epoch = 13, train_acc = 0.9343333, train_loss = 0.1849418, test_acc = 0.9129000, time = 6.2959280\n",
      "epoch = 14, train_acc = 0.9367333, train_loss = 0.1784230, test_acc = 0.9087000, time = 6.2196271\n",
      "epoch = 15, train_acc = 0.9396667, train_loss = 0.1710586, test_acc = 0.9125000, time = 6.1994331\n",
      "epoch = 16, train_acc = 0.9400333, train_loss = 0.1658103, test_acc = 0.9155000, time = 6.1455083\n",
      "epoch = 17, train_acc = 0.9433333, train_loss = 0.1612006, test_acc = 0.9154000, time = 5.9866862\n",
      "epoch = 18, train_acc = 0.9456167, train_loss = 0.1524187, test_acc = 0.9152000, time = 6.1951363\n",
      "epoch = 19, train_acc = 0.9472833, train_loss = 0.1477410, test_acc = 0.9143000, time = 6.4147699\n",
      "epoch = 20, train_acc = 0.9484333, train_loss = 0.1424513, test_acc = 0.9168000, time = 6.1581247\n"
     ]
    }
   ],
   "source": [
    "train_net(train, test, model, epochs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b89f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
